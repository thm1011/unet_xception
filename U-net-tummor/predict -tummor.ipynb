{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # -1 cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In /root/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /root/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /root/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n",
    "from nets import unet\n",
    "from nets.unet_xception import UnetXception\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from openslide import OpenSlide\n",
    "import csv, glob\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from keras.backend.tensorflow_backend import set_session  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))  \n",
    "import cv2\n",
    "import pandas as pd\n",
    "from data_loader import TestGenerator\n",
    "from extract_patches_module_simple import read_wsi_regions, construct_colored_wsi\n",
    "from crop_image import image_padding, joint_image\n",
    "import glob\n",
    "import keras\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'test_IHC/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_file = []\n",
    "exts = ['.tiff', '.tif']\n",
    "\n",
    "for ext in exts:\n",
    "    img_file += glob.glob(os.path.join(file_path, '*' + ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'result'\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "result_path = os.path.join('result/', 'test_{:02d}{:02d}'.format(today.month, today.day))\n",
    "# result_path = 'datasets/test_1130/'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_model(model_dir):\n",
    "    models = os.listdir(model_dir)\n",
    "    best_file = ''\n",
    "    best_loss = float('inf')\n",
    "    for m in models:\n",
    "        match = re.search( r'val_loss(.*).h5', m, re.M|re.I)\n",
    "        if match is None:\n",
    "            continue\n",
    "        val_loss = float(match.group(1))\n",
    "        if val_loss < best_loss:\n",
    "            best_file = m\n",
    "    return best_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'logs_512/20230605/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ep146-loss0.064-val_loss0.065.h5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "unet = UnetXception(num_classes = 2, drop_rate = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unet.load_weights(os.path.join(model_path, get_best_model(model_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##tissue_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_image(patch_image, item_width, col, row):\n",
    "    target_size = (int(col * item_width), int(row * item_width))\n",
    "    print(item_width, col, row)\n",
    "    result_image = Image.new('RGB', target_size, (255, 255, 255))\n",
    "    for index, s_image in enumerate(patch_image):\n",
    "        h = int(index/col)\n",
    "        w = index%col\n",
    "        result_image.paste(s_image,(w*item_width, h*item_width))\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_padding(input_image, item_width):\n",
    "    #iw, ih = input_image.size\n",
    "    iw = np.size(input_image,1)\n",
    "    ih = np.size(input_image,0)\n",
    "    col = int(np.ceil(iw/item_width))\n",
    "    row = int(np.ceil(ih/item_width))  #网络的输入为正方形，所以item_width=item_height\n",
    "    target_size = (int(col*item_width), int(row*item_width))\n",
    "    image = Image.new('RGB', target_size, \"white\")\n",
    "    image.paste(input_image, (0, 0))\n",
    "    return image, col, row\n",
    "\n",
    "\n",
    "def cut_image(image, col, row, item_width):\n",
    "    box_list = []\n",
    "    count = 0\n",
    "    for j in range(0, row):\n",
    "        for i in range(0, col):\n",
    "            count += 1\n",
    "            box = (i * item_width, j * item_width, (i + 1) * item_width, (j + 1) * item_width)\n",
    "            box_list.append(box)\n",
    "    image_list = []\n",
    "    for box in box_list:\n",
    "        tmp = image.crop(box)\n",
    "        if tmp.size!=(item_width, item_width):\n",
    "            tmp = image_padding(tmp, item_width)[0]\n",
    "        image_list.append(tmp)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_wsi(wsi,level_idx, relative_scale):\n",
    "    wsi_imgs = wsi.read_region((0, 0), level_idx, wsi.level_dimensions[level_idx])\n",
    "    wsi_imgs = construct_colored_wsi(wsi_imgs, return_array=False)\n",
    "    if relative_scale!=1:\n",
    "        wsi_imgs = wsi_imgs.resize((int(wsi_imgs.size[0]//relative_scale), int(wsi_imgs.size[1]//relative_scale)))\n",
    "    return wsi_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downsample_tissue(file, required_px_size = 8):\n",
    "    # 8μm == downsample 16 in mpp 0.5μm/pixel\n",
    "    wsi = OpenSlide(file)\n",
    "    mpp = float(wsi.properties[\"openslide.mpp-x\"])\n",
    "    downsample = required_px_size / mpp\n",
    "    relative_scale = 1\n",
    "    level_downsamples = np.array(wsi.level_downsamples)\n",
    "    if downsample < level_downsamples[0]:\n",
    "        return wsi, 0, 1\n",
    "    for i in range(1, len(level_downsamples)):\n",
    "        if downsample < level_downsamples[i] : \n",
    "            if level_downsamples[i] - downsample < 1:  # closer to level_downsamples[i]\n",
    "                return wsi, i, 1\n",
    "            else:\n",
    "                relative_scale = downsample / level_downsamples[i-1]\n",
    "                if relative_scale <= 1.5:\n",
    "                    relative_scale = 1\n",
    "                return wsi, i-1, relative_scale\n",
    "\n",
    "    relative_scale = downsample / level_downsamples[len(level_downsamples) - 1]\n",
    "    if relative_scale <= 1.5:\n",
    "        relative_scale = 1\n",
    "    return wsi, len(level_downsamples)-1, relative_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_level(wsi,level_idx):\n",
    "    level_id=2**(level_idx)\n",
    "    mpp=float(wsi.properties[openslide.PROPERTY_NAME_MPP_X])\n",
    "    total_level=level_id* mpp\n",
    "    return total_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumor_areas(img_file,model_path):\n",
    "    for i,file in enumerate(img_file):\n",
    "        print('Start' + file, end = ',')\n",
    "        start =time.time()\n",
    "        wsi,level_idx, relative_scale=get_downsample_tissue(file)\n",
    "        end1 = time.time()\n",
    "        wsi_imgs=get_required_wsi(wsi,level_idx, relative_scale)\n",
    "        width, height = wsi_imgs.size\n",
    "        row = math.ceil(height / 512)\n",
    "        col = math.ceil(width / 512)\n",
    "        patches_512 = cut_image(wsi_imgs, col, row, 512)\n",
    "        patches_512 = [np.asarray(p) for p in patches_512]\n",
    "        print('read: {:.2f}'.format(end1 - start), end = ', ')\n",
    "        unet.load_weights(os.path.join(model_path, get_best_model(model_path)))\n",
    "        image_512_gen = TestGenerator(patches_512, 512, batch_size, is_cls=False)\n",
    "        masks = unet.predict_generator(image_512_gen, use_multiprocessing=False, workers=4)\n",
    "        total=get_wsi_level(wsi,level_idx)\n",
    "        masks = np.argmax(masks, axis=-1)\n",
    "        result_image_list = []\n",
    "        area_list=[]\n",
    "        for i, image in enumerate(patches_512):\n",
    "            mask_arr=sum(masks[i])\n",
    "            #area=(sum(mask_arr))*total*total \n",
    "            area=(np.sum(mask_arr))*total*total \n",
    "            color_mask = np.array([255, 0, 0], dtype='uint8')\n",
    "            mask_img = np.where(masks[i][..., None], color_mask, np.asarray(image))\n",
    "            img_new = cv2.addWeighted(np.asarray(image), 0.7, mask_img, 0.3, 0)\n",
    "            image = Image.fromarray(img_new)\n",
    "            result_image_list.append(image)\n",
    "            area_list.append(area)\n",
    "        Areas=sum(area_list)\n",
    "        with open('Area_HE.csv', 'a', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([file,Areas])\n",
    "        result_image = joint_image(result_image_list, 512, col, row)\n",
    "        result_image = result_image.crop((0,0,width,height))\n",
    "        w = result_image.size[0]\n",
    "        h = result_image.size[1]\n",
    "        if w < 40000 and h<40000: \n",
    "            try:  \n",
    "                result_image.save(os.path.join(result_path, os.path.splitext(os.path.basename(file))[0] + '.jpg'))\n",
    "                print('save successfully!  Total time: ', time.time() - start)\n",
    "            except:\n",
    "                print('save failed 1!  Total time: ', time.time() - start)\n",
    "        else:\n",
    "            if w < 60000:\n",
    "                try:\n",
    "                    boxes = [(0, 0,w//2, int(h/2)), (int(w/2), 0, w, int(h/2)), (0, int(h/2), int(w/2), h), (int(w/2), int(h/2), w, h)]\n",
    "                    for i in range(4):\n",
    "                        result_image.crop(boxes[i]).save(os.path.join(result_path, os.path.splitext(os.path.basename(file))[0] + '_' + str(i+1) +  '.jpg'))\n",
    "                    print('save successfully crop 4 parts!  Total time: ' , time.time() - start)\n",
    "                except:\n",
    "                    print('save failed 2!  Total time: ', time.time() - start)\n",
    "            else:\n",
    "                try:\n",
    "                    boxes = [(0, 0, w//3, h//2), (w//3, 0, w//3*2, h//2), (w//3*2, 0, w, h//2),\n",
    "                         (0, h//2, w//3, h), (w//3, h//2, w//3*2, h), (w//3*2, h//2, w, h)]\n",
    "                    for i in range(6):\n",
    "                        result_image.crop(boxes[i]).save(os.path.join(result_path, os.path.splitext(os.path.basename(file))[0] + '_' + str(i+1) +  '.jpg'))\n",
    "\n",
    "                    print('save successfully crop 6 parts!  Total time: ' , time.time() - start)\n",
    "                except:\n",
    "                    print('save failed 3!  Total time: ', time.time() - start)\n",
    "    return result_image,Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starttest_IHC/100597S01X2_IHC.tif,read: 0.00, 512 4 4\n",
      "save successfully!  Total time:  5.38815712928772\n",
      "Starttest_IHC/100013S01_HE.tif,read: 0.00, 512 3 2\n",
      "save successfully!  Total time:  2.782843589782715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=1502x955>, 40578138.92543965)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_areas(img_file,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openslide import OpenSlide, OpenSlideUnsupportedFormatError\n",
    "import numpy as np\n",
    "import openslide\n",
    "a = OpenSlide('./20230718/1000384S01_HE.tif')\n",
    "a.level_dimensions\n",
    "b=a.level_dimensions[4]\n",
    "print(b)\n",
    "lrHeight = a.level_dimensions[4][1]\n",
    "lrWidth = a.level_dimensions[4][0]\n",
    "mmx = a.properties['openslide.mpp-x']\n",
    "print(lrHeight,lrWidth,mmx)\n",
    "np.abs((np.array(a.level_downsamples) -16)).argmin()\n",
    "np.abs((np.array(a.level_downsamples) -16))\n",
    "a.properties\n",
    "a.read_region((0, 0), 4, (512,512)).size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
