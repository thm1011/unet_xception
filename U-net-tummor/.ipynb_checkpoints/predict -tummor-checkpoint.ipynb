{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # -1 cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "In /root/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /root/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In /root/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"Passing\", category=FutureWarning)\n",
    "from nets import unet\n",
    "from nets.unet_xception import UnetXception\n",
    "from PIL import Image, ImageFile\n",
    "import numpy as np\n",
    "from openslide import OpenSlide\n",
    "import csv, glob\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "from keras.backend.tensorflow_backend import set_session  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))  \n",
    "import cv2\n",
    "import pandas as pd\n",
    "from data_loader import TestGenerator\n",
    "from extract_patches_module_simple import read_wsi_regions, construct_colored_wsi\n",
    "from crop_image import image_padding, joint_image\n",
    "import glob\n",
    "import keras\n",
    "from pathlib import Path\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/data/chenshiting/PD-L1/PD-L1-cls-unet/extract_patches_module/')\n",
    "from openslide import OpenSlide, OpenSlideUnsupportedFormatError\n",
    "import openslide\n",
    "from openslide_python_fix import _load_image_lessthan_2_29, _load_image_morethan_2_29\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session  \n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth = True  \n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "set_session(tf.Session(config=config))  \n",
    "from pathlib import Path\n",
    "import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import plot\n",
    "import csv\n",
    "from cellpose_mbn import CellposeMBN\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import multiprocessing\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "from PIL import Image\n",
    "import datetime\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '20230718/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_file = []\n",
    "exts = ['.tiff', '.tif']\n",
    "\n",
    "for ext in exts:\n",
    "    img_file += glob.glob(os.path.join(file_path, '*' + ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'result'\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today()\n",
    "result_path = os.path.join('result/', 'test_{:02d}{:02d}'.format(today.month, today.day))\n",
    "# result_path = 'datasets/test_1130/'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_best_model(model_dir):\n",
    "    models = os.listdir(model_dir)\n",
    "    best_file = ''\n",
    "    best_loss = float('inf')\n",
    "    for m in models:\n",
    "        match = re.search( r'val_loss(.*).h5', m, re.M|re.I)\n",
    "        if match is None:\n",
    "            continue\n",
    "        val_loss = float(match.group(1))\n",
    "        if val_loss < best_loss:\n",
    "            best_file = m\n",
    "    return best_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'logs_512/20230721_HE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ep126-loss0.044-val_loss0.037.h5'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "unet = UnetXception(num_classes = 2, drop_rate = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unet.load_weights(os.path.join(model_path, get_best_model(model_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openslide import OpenSlide, OpenSlideUnsupportedFormatError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = OpenSlide('./20230718/1000384S01_HE.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22034, 16381),\n",
       " (11017, 8190),\n",
       " (5508, 4095),\n",
       " (2754, 2047),\n",
       " (1377, 1021),\n",
       " (688, 510))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.level_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1377, 1021)\n"
     ]
    }
   ],
   "source": [
    "b=a.level_dimensions[4]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrHeight = a.level_dimensions[4][1]\n",
    "lrWidth = a.level_dimensions[4][0]\n",
    "mmx = a.properties['openslide.mpp-x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1021 1377 0.48643700000000001\n"
     ]
    }
   ],
   "source": [
    "print(lrHeight,lrWidth,mmx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs((np.array(a.level_downsamples) -16)).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15.        , 13.99993895, 11.99969635,  7.99841559,  0.02276343,\n",
       "       16.07288532])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs((np.array(a.level_downsamples) -16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PropertyMap {'aperio.AppMag': '20', 'aperio.MPP': '0.486437', 'aperio.Time': '12:28:18', 'aperio.Time-Used': '\\x17,:/.:�0', 'aperio.User': 'KFPBL12000109004', 'openslide.comment': 'Aperio Format Scanned By KFBIO\\r\\n22034x16346 [0,0 22034x16346] (256x256), JPEG/RGB Q=30|AppMag = 20|MPP = 0.486437|User = KFPBL12000109004|Time = 12:28:18|Time-Used = \\x17,:/.:�0', 'openslide.level-count': '6', 'openslide.level[0].downsample': '1', 'openslide.level[0].height': '16381', 'openslide.level[0].tile-height': '256', 'openslide.level[0].tile-width': '256', 'openslide.level[0].width': '22034', 'openslide.level[1].downsample': '2.0000610500610501', 'openslide.level[1].height': '8190', 'openslide.level[1].tile-height': '256', 'openslide.level[1].tile-width': '256', 'openslide.level[1].width': '11017', 'openslide.level[2].downsample': '4.000303654225223', 'openslide.level[2].height': '4095', 'openslide.level[2].tile-height': '256', 'openslide.level[2].tile-width': '256', 'openslide.level[2].width': '5508', 'openslide.level[3].downsample': '8.001584407668874', 'openslide.level[3].height': '2047', 'openslide.level[3].tile-height': '256', 'openslide.level[3].tile-width': '256', 'openslide.level[3].width': '2754', 'openslide.level[4].downsample': '16.022763434825812', 'openslide.level[4].height': '1021', 'openslide.level[4].tile-height': '256', 'openslide.level[4].tile-width': '256', 'openslide.level[4].width': '1377', 'openslide.level[5].downsample': '32.072885316917464', 'openslide.level[5].height': '510', 'openslide.level[5].tile-height': '256', 'openslide.level[5].tile-width': '256', 'openslide.level[5].width': '688', 'openslide.mpp-x': '0.48643700000000001', 'openslide.mpp-y': '0.48643700000000001', 'openslide.objective-power': '20', 'openslide.quickhash-1': '8c1c8467b92cccb1959dbecc6cab09f6461ef2d2996d93de4cd27f42544fa791', 'openslide.vendor': 'aperio', 'tiff.Artist': 'KFBIO', 'tiff.ImageDescription': 'Aperio Format Scanned By KFBIO\\r\\n22034x16346 [0,0 22034x16346] (256x256), JPEG/RGB Q=30|AppMag = 20|MPP = 0.486437|User = KFPBL12000109004|Time = 12:28:18|Time-Used = \\x17,:/.:�0', 'tiff.ResolutionUnit': 'inch'}>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.read_region((0, 0), 4, (512,512)).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##tissue_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_image(patch_image, item_width, col, row):\n",
    "    target_size = (int(col * item_width), int(row * item_width))\n",
    "    print(item_width, col, row)\n",
    "    result_image = Image.new('RGB', target_size, (255, 255, 255))\n",
    "    for index, s_image in enumerate(patch_image):\n",
    "        h = int(index/col)\n",
    "        w = index%col\n",
    "        result_image.paste(s_image,(w*item_width, h*item_width))\n",
    "    return result_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_padding(input_image, item_width):\n",
    "    #iw, ih = input_image.size\n",
    "    iw = np.size(input_image,1)\n",
    "    ih = np.size(input_image,0)\n",
    "    col = int(np.ceil(iw/item_width))\n",
    "    row = int(np.ceil(ih/item_width))  #网络的输入为正方形，所以item_width=item_height\n",
    "    target_size = (int(col*item_width), int(row*item_width))\n",
    "    image = Image.new('RGB', target_size, \"white\")\n",
    "    image.paste(input_image, (0, 0))\n",
    "    return image, col, row\n",
    "\n",
    "\n",
    "def cut_image(image, col, row, item_width):\n",
    "    box_list = []\n",
    "    count = 0\n",
    "    for j in range(0, row):\n",
    "        for i in range(0, col):\n",
    "            count += 1\n",
    "            box = (i * item_width, j * item_width, (i + 1) * item_width, (j + 1) * item_width)\n",
    "            box_list.append(box)\n",
    "    image_list = []\n",
    "    for box in box_list:\n",
    "        tmp = image.crop(box)\n",
    "        if tmp.size!=(item_width, item_width):\n",
    "            tmp = image_padding(tmp, item_width)[0]\n",
    "        image_list.append(tmp)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_required_wsi(wsi,level_idx, relative_scale):\n",
    "    wsi_imgs = wsi.read_region((0, 0), level_idx, wsi.level_dimensions[level_idx])\n",
    "    wsi_imgs = construct_colored_wsi(wsi_imgs, return_array=False)\n",
    "    if relative_scale!=1:\n",
    "        wsi_imgs = wsi_imgs.resize((int(wsi_imgs.size[0]//relative_scale), int(wsi_imgs.size[1]//relative_scale)))\n",
    "    return wsi_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_downsample_tissue(file, required_px_size = 8):\n",
    "    # 8μm == downsample 16 in mpp 0.5μm/pixel\n",
    "    wsi = OpenSlide(file)\n",
    "    mpp = float(wsi.properties[\"openslide.mpp-x\"])\n",
    "    downsample = required_px_size / mpp\n",
    "    relative_scale = 1\n",
    "    level_downsamples = np.array(wsi.level_downsamples)\n",
    "    if downsample < level_downsamples[0]:\n",
    "        return wsi, 0, 1\n",
    "    for i in range(1, len(level_downsamples)):\n",
    "        if downsample < level_downsamples[i] : \n",
    "            if level_downsamples[i] - downsample < 1:  # closer to level_downsamples[i]\n",
    "                return wsi, i, 1\n",
    "            else:\n",
    "                relative_scale = downsample / level_downsamples[i-1]\n",
    "                if relative_scale <= 1.5:\n",
    "                    relative_scale = 1\n",
    "                return wsi, i-1, relative_scale\n",
    "\n",
    "    relative_scale = downsample / level_downsamples[len(level_downsamples) - 1]\n",
    "    if relative_scale <= 1.5:\n",
    "        relative_scale = 1\n",
    "    return wsi, len(level_downsamples)-1, relative_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wsi_level(wsi,level_idx):\n",
    "    level_id=2**(level_idx)\n",
    "    mpp=float(wsi.properties[openslide.PROPERTY_NAME_MPP_X])\n",
    "    total_level=level_id* mpp\n",
    "    return total_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tumor_areas(img_file,model_path):\n",
    "    for i,file in enumerate(img_file):\n",
    "        print('Start' + file, end = ',')\n",
    "        start =time.time()\n",
    "        wsi,level_idx, relative_scale=get_downsample_tissue(file)\n",
    "        end1 = time.time()\n",
    "        wsi_imgs=get_required_wsi(wsi,level_idx, relative_scale)\n",
    "        width, height = wsi_imgs.size\n",
    "        row = math.ceil(height / 512)\n",
    "        col = math.ceil(width / 512)\n",
    "        patches_512 = cut_image(wsi_imgs, col, row, 512)\n",
    "        patches_512 = [np.asarray(p) for p in patches_512]\n",
    "        print('read: {:.2f}'.format(end1 - start), end = ', ')\n",
    "        unet.load_weights(os.path.join(model_path, get_best_model(model_path)))\n",
    "        image_512_gen = TestGenerator(patches_512, 512, batch_size, is_cls=False)\n",
    "        masks = unet.predict_generator(image_512_gen, use_multiprocessing=False, workers=4)\n",
    "        total=get_wsi_level(wsi,level_idx)\n",
    "        masks = np.argmax(masks, axis=-1)\n",
    "        result_image_list = []\n",
    "        area_list=[]\n",
    "        for i, image in enumerate(patches_512):\n",
    "            mask_arr=sum(masks[i])\n",
    "            #area=(sum(mask_arr))*total*total \n",
    "            area=(np.sum(mask_arr))*total*total \n",
    "            color_mask = np.array([255, 0, 0], dtype='uint8')\n",
    "            mask_img = np.where(masks[i][..., None], color_mask, np.asarray(image))\n",
    "            img_new = cv2.addWeighted(np.asarray(image), 0.7, mask_img, 0.3, 0)\n",
    "            image = Image.fromarray(img_new)\n",
    "            result_image_list.append(image)\n",
    "            area_list.append(area)\n",
    "        Areas=sum(area_list)\n",
    "        with open('Area_HE.csv', 'a', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([file,Areas])\n",
    "        result_image = joint_image(result_image_list, 512, col, row)\n",
    "        result_image = result_image.crop((0,0,width,height))\n",
    "        w = result_image.size[0]\n",
    "        h = result_image.size[1]\n",
    "        if w < 40000 and h<40000: \n",
    "            try:  \n",
    "                result_image.save(os.path.join(result_path, os.path.splitext(os.path.basename(file))[0] + '.jpg'))\n",
    "                print('save successfully!  Total time: ', time.time() - start)\n",
    "            except:\n",
    "                print('save failed 1!  Total time: ', time.time() - start)\n",
    "        else:\n",
    "            if w < 60000:\n",
    "                try:\n",
    "                    boxes = [(0, 0,w//2, int(h/2)), (int(w/2), 0, w, int(h/2)), (0, int(h/2), int(w/2), h), (int(w/2), int(h/2), w, h)]\n",
    "                    for i in range(4):\n",
    "                        result_image.crop(boxes[i]).save(os.path.join(result_path, os.path.splitext(os.path.basename(file))[0] + '_' + str(i+1) +  '.jpg'))\n",
    "                    print('save successfully crop 4 parts!  Total time: ' , time.time() - start)\n",
    "                except:\n",
    "                    print('save failed 2!  Total time: ', time.time() - start)\n",
    "            else:\n",
    "                try:\n",
    "                    boxes = [(0, 0, w//3, h//2), (w//3, 0, w//3*2, h//2), (w//3*2, 0, w, h//2),\n",
    "                         (0, h//2, w//3, h), (w//3, h//2, w//3*2, h), (w//3*2, h//2, w, h)]\n",
    "                    for i in range(6):\n",
    "                        result_image.crop(boxes[i]).save(os.path.join(result_path, os.path.splitext(os.path.basename(file))[0] + '_' + str(i+1) +  '.jpg'))\n",
    "\n",
    "                    print('save successfully crop 6 parts!  Total time: ' , time.time() - start)\n",
    "                except:\n",
    "                    print('save failed 3!  Total time: ', time.time() - start)\n",
    "    return result_image,Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start20230718/1000384S01_HE.tif,read: 0.00, 7.782992\n",
      "512 3 2\n",
      "save successfully!  Total time:  0.4859147071838379\n",
      "Start20230718/100013S01_HE.tif,read: 0.00, 7.782992\n",
      "512 3 2\n",
      "save successfully!  Total time:  0.4768667221069336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=1502x955>, 42802693.920711726)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_areas(img_file,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wsi(tif_file_path, level):\n",
    "    \n",
    "    '''\n",
    "        Identify and load slides.\n",
    "        Returns:\n",
    "            - wsi_image: OpenSlide object.\n",
    "            - rgba_image: WSI image loaded, NumPy array type.\n",
    "    '''\n",
    "    \n",
    "    # time_s = time.time()\n",
    "    \n",
    "    try:\n",
    "        wsi_image = OpenSlide(tif_file_path)\n",
    "        #DAB_angle, H_angle = getHDabEstimate(wsi_image)\n",
    "        DAB_angle = -1\n",
    "        H_angle = -1\n",
    "        slide_w_, slide_h_ = wsi_image.level_dimensions[level]\n",
    "        \n",
    "        # Check which _load_image() function to use depending on the size of the region.\n",
    "        if (slide_w_ * slide_h_) >= 2**29:\n",
    "            openslide.lowlevel._load_image = _load_image_morethan_2_29\n",
    "        else:\n",
    "            openslide.lowlevel._load_image = _load_image_lessthan_2_29\n",
    "        \n",
    "        '''\n",
    "            The read_region loads the target area into RAM memory, and\n",
    "            returns an Pillow Image object.\n",
    "\n",
    "            !! Take care because WSIs are gigapixel images, which are could be \n",
    "            extremely large to RAMs.\n",
    "\n",
    "            Load the whole image in level < 3 could cause failures.\n",
    "        '''\n",
    "\n",
    "        # Here we load the whole image from (0, 0), so transformation of coordinates \n",
    "        # is not skipped.\n",
    "\n",
    "        rgba_image_pil = wsi_image.read_region((0, 0), level, (slide_w_, slide_h_))\n",
    "        # verboseprint(\"width, height:\", rgba_image_pil.size)\n",
    "\n",
    "        '''\n",
    "            !!! It should be noted that:\n",
    "            1. np.asarray() / np.array() would switch the position \n",
    "            of WIDTH and HEIGHT in shape.\n",
    "\n",
    "            Here, the shape of $rgb_image_pil is: (WIDTH, HEIGHT, channel).\n",
    "            After the np.asarray() transformation, the shape of $rgb_image is: \n",
    "            (HEIGHT, WIDTH, channel).\n",
    "\n",
    "            2. The image here is RGBA image, in which A stands for Alpha channel.\n",
    "            The A channel is unnecessary for now and could be dropped.\n",
    "        '''\n",
    "        rgba_image = np.asarray(rgba_image_pil)\n",
    "        r_, g_, b_, a_ = cv2.split(rgba_image)\n",
    "    \n",
    "        wsi_rgb_ = cv2.merge((r_, g_, b_))\n",
    "        \n",
    "        # verboseprint(\"transformed:\", rgba_image.shape)\n",
    "        \n",
    "    except OpenSlideUnsupportedFormatError:\n",
    "        print('Exception: OpenSlideUnsupportedFormatError')\n",
    "        return None\n",
    "\n",
    "    # time_e = time.time()\n",
    "    \n",
    "    # verboseprint(\"Time spent on loading\", tif_file_path, \": \", (time_e - time_s))\n",
    "    \n",
    "    return wsi_rgb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_images(img, patch_size, normalize=True, overlap=32, invert=False):\n",
    "    if normalize:\n",
    "        img = transforms.normalize_img(img, invert=invert)\n",
    "        \n",
    "    boxes = []\n",
    "    slide_h_, slide_w_ = img.shape[0], img.shape[1]\n",
    "    for y in range(0, math.ceil(slide_h_ / patch_size)):\n",
    "        for x in range(0, math.ceil(slide_w_ / patch_size)):\n",
    "            xMin, yMin = x * patch_size, y * patch_size \n",
    "            xMax, yMax = xMin + patch_size, yMin + patch_size\n",
    "            xMin = max(0, xMin - overlap)\n",
    "            yMin = max(0, yMin - overlap)\n",
    "            xMax = min(slide_w_, xMax + overlap)\n",
    "            yMax = min(slide_h_, yMax + overlap)\n",
    "            patch_width = xMax - xMin\n",
    "            patch_height = yMax - yMin\n",
    "            boxes.append((xMin, yMin, patch_width, patch_height))\n",
    "    rows, cols = math.ceil(slide_h_ / patch_size), math.ceil(slide_w_ / patch_size)\n",
    "    \n",
    "    def cut(box):\n",
    "        xMin, yMin, patch_width, patch_height = box\n",
    "        if xMin >= slide_w_ or yMin >= slide_h_:\n",
    "            return None\n",
    "        return img[yMin: yMin + patch_height, xMin:xMin+patch_width].copy()\n",
    "    \n",
    "    pool = ThreadPool(multiprocessing.cpu_count() - 1)\n",
    "    patches = pool.map(cut, boxes)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return patches, slide_w_, slide_h_, cols, rows, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "cp = CellposeMBN(image_size=None, diam_mean=30, diam_label=25, nchans=3,  less_block=False, \n",
    "                   pretrained_model='../cellpose-mbn/logs/nuclei_HE_20230725_mbn_noAug/ep0968-loss0.497-val_loss0.491.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap_patch_idx(patch_idx, cols, rows):\n",
    "    row_idx = patch_idx // cols \n",
    "    col_idx = patch_idx % cols\n",
    "    overlapped_idxs = []\n",
    "    for row in [row_idx-1, row_idx, row_idx + 1]:\n",
    "        for col in [col_idx-1, col_idx, col_idx+1]:\n",
    "            if row > rows - 1 or row < 0:\n",
    "                continue\n",
    "            if col > cols - 1 or col < 0:\n",
    "                continue\n",
    "            idx = row * cols + col\n",
    "            if idx!=patch_idx:\n",
    "                overlapped_idxs.append(idx)\n",
    "    return overlapped_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlines_list(masks, offset_x, offset_y):\n",
    "    \"\"\" get outlines of masks as a list to loop over for plotting \"\"\"\n",
    "    outlines = []\n",
    "    for n in np.unique(masks)[1:]:\n",
    "        mn = masks == n\n",
    "        if mn.sum() > 0:\n",
    "            contours = cv2.findContours(mn.astype(np.uint8), mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "            contours = contours[-2]\n",
    "            cmax = np.argmax([c.shape[0] for c in contours])\n",
    "            pix = contours[cmax].astype(int).squeeze()\n",
    "            if len(pix) > 4:\n",
    "                outlines.append(pix + (offset_x, offset_y))\n",
    "    return outlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_overlap(mask1, mask2, patch_xMin1, patch_yMin1, patch_xMin2, patch_yMin2):\n",
    "    nmask1 = mask1.max()\n",
    "    nmask2 = mask2.max()\n",
    "    canvas_xmin, canvas_ymin = min(patch_xMin1, patch_xMin2), min(patch_yMin1, patch_yMin2)\n",
    "    canvas_xmax, canvas_ymax = max(patch_xMin1+mask1.shape[1], patch_xMin2+mask2.shape[1]),max(patch_yMin1+mask1.shape[0], patch_yMin2+mask2.shape[0]) \n",
    "    \n",
    "    # overlap_area = np.zeros((nmask1, nmask2))\n",
    "    mask1_y_rel, mask1_x_rel = patch_yMin1-canvas_ymin, patch_xMin1-canvas_xmin\n",
    "    mask2_y_rel, mask2_x_rel = patch_yMin2-canvas_ymin, patch_xMin2-canvas_xmin\n",
    "    for i in range(1, nmask1):\n",
    "        area1 = (mask1==i).sum()\n",
    "        canvas1 = np.zeros((canvas_ymax - canvas_ymin, canvas_xmax - canvas_xmin))\n",
    "        canvas2 = np.zeros((canvas_ymax - canvas_ymin, canvas_xmax - canvas_xmin))\n",
    "        if not (mask1==i).any():\n",
    "            continue\n",
    "        mask2_area = np.bincount(mask2.reshape(-1))\n",
    "        if mask2_area.shape[0] <= 1:\n",
    "            continue\n",
    "        mask2_area = mask2_area[1:]\n",
    "        \n",
    "        canvas1[mask1_y_rel:(mask1_y_rel+mask1.shape[0]), \n",
    "               mask1_x_rel:(mask1_x_rel+mask1.shape[1])] = mask1 == i\n",
    "        canvas2[mask2_y_rel:(mask2_y_rel+mask2.shape[0]), \n",
    "               mask2_x_rel:(mask2_x_rel+mask2.shape[1])] = mask2\n",
    "        canvas = (canvas1 * canvas2).astype('int64')\n",
    "        mask2_area = np.bincount(mask2.reshape(-1))[1:]\n",
    "        overlap_area = np.bincount(canvas[mask2_y_rel:(mask2_y_rel+mask2.shape[0]), \n",
    "                                          mask2_x_rel:(mask2_x_rel+mask2.shape[1])].reshape(-1))\n",
    "        if overlap_area.shape[0] <= 1:\n",
    "            continue\n",
    "        overlap_area = overlap_area[1:]\n",
    "        # print(len(overlap_area), patch_xMin1, patch_yMin1, patch_xMin2, patch_yMin2)\n",
    "        \n",
    "        for o_idx in range(len(overlap_area)):\n",
    "            if mask2_area[o_idx] > area1:\n",
    "                if overlap_area[o_idx] > area1/2:\n",
    "                    mask1[mask1==i] = 0\n",
    "                    # continue\n",
    "                else:\n",
    "                    mask1[canvas[mask1_y_rel:(mask1_y_rel+mask1.shape[0]), \n",
    "                                 mask1_x_rel:(mask1_x_rel+mask1.shape[1])] == o_idx + 1] = 0\n",
    "            else:\n",
    "                if overlap_area[o_idx] > mask2_area[o_idx]/2:\n",
    "                    mask2[mask2 == o_idx+1] = 0\n",
    "                else:\n",
    "                    mask2[canvas[mask2_y_rel:(mask2_y_rel+mask2.shape[0]), \n",
    "                                 mask2_x_rel:(mask2_x_rel+mask2.shape[1])] == o_idx + 1] = 0                   \n",
    "    return mask1, mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_downsample_cell(file, required_px_size = 0.5):\n",
    "    # 8μm == downsample 16 in mpp 0.5μm/pixel\n",
    "    wsi = OpenSlide(file)\n",
    "    mpp = float(wsi.properties[\"openslide.mpp-x\"])\n",
    "    downsample = required_px_size / mpp\n",
    "    relative_scale = 1\n",
    "    level_downsamples = np.array(wsi.level_downsamples)\n",
    "    if downsample < level_downsamples[0]:\n",
    "        return wsi, 0, 1\n",
    "    for i in range(1, len(level_downsamples)):\n",
    "        if downsample < level_downsamples[i] : \n",
    "            if level_downsamples[i] - downsample < 1:  # closer to level_downsamples[i]\n",
    "                return wsi, i, 1\n",
    "            else:\n",
    "                relative_scale = downsample / level_downsamples[i-1]\n",
    "                if relative_scale <= 1.5:\n",
    "                    relative_scale = 1\n",
    "                return wsi, i-1, relative_scale\n",
    "\n",
    "    relative_scale = downsample / level_downsamples[len(level_downsamples) - 1]\n",
    "    if relative_scale <= 1.5:\n",
    "        relative_scale = 1\n",
    "    return wsi, len(level_downsamples)-1, relative_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_foreground(mask_tissue:np.ndarray, patch_xMin, patch_yMin, patch_width, patch_height, downsample_tissue, downsample_cell):\n",
    "    downsample = downsample_tissue / downsample_cell\n",
    "    patch_xMin = int(patch_xMin / downsample)\n",
    "    patch_yMin = int(patch_yMin/downsample)\n",
    "    patch_width = int(patch_width/downsample)\n",
    "    patch_height = int(patch_height/downsample)\n",
    "    arr = mask_tissue[patch_yMin:patch_yMin + patch_height, patch_xMin: patch_xMin + patch_width]\n",
    "    #cell_arr=Image.fromarray(arr)\n",
    "    return (arr>=1).any() # true or flase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cell_wsi_area(img_file):\n",
    "    for i,file in enumerate(img_file):\n",
    "        if os.path.exists(os.path.join(output_path, file)):\n",
    "            continue\n",
    "        wsi_tissue,level_idx_tissue, relative_scale_tissue=get_downsample_tissue(file)\n",
    "        tissue_downsample=wsi_tissue.level_downsamples[level_idx_tissue] * relative_scale_tissue\n",
    "        wsi_cell,level_idx_cell, relative_scale_cell=get_downsample_cell(file)\n",
    "        cell_downsample=wsi_cell.level_downsamples[level_idx_cell] * relative_scale_cell\n",
    "        #print(wsi_tissue.level_downsamples[level_idx_tissue], wsi_cell.level_downsamples[level_idx_cell])\n",
    "        #print(tissue_downsample, cell_downsample)\n",
    "        mask_tissue,tissue_area=tumor_areas(img_file,model_path)\n",
    "        mask_tissue_arr=np.array(mask_tissue)\n",
    "        wsi_img = read_wsi(file,level_idx_cell)\n",
    "        patches, slide_w, slide_h, cols, rows, patches_coord =  cut_images(wsi_img, 256, normalize=True, overlap=32)\n",
    "        #wsi_arr=is_foreground(mask_tissue_arr,patches_coord[i][0],patches_coord[i][1], patches_coord[i][2],patches_coord[i][3],level_idx_tissue,level_idx_cell)\n",
    "        #cell_arr=Image.fromarray(wsi_arr)\n",
    "        #print(len(patches_coord ))\n",
    "        fg_indexes=[]\n",
    "        fg_patches = []\n",
    "        for i in (range(len(patches_coord))):\n",
    "            is_fg =is_foreground(mask_tissue_arr,patches_coord[i][0],patches_coord[i][1], patches_coord[i][2],patches_coord[i][3],tissue_downsample, cell_downsample)\n",
    "            if is_fg:\n",
    "                fg_indexes.append(i)\n",
    "                fg_patches.append(patches[i])\n",
    "        #print(len(fg_indexes),len(fg_patches),len(patches_coord))\n",
    "        start = time.time()\n",
    "        # TODO patches --> fg_patches\n",
    "        masks, _ = cp.eval(fg_patches, batch_size=8, diameter=25, cellprob_threshold=1.0, flow_threshold=0.6, \n",
    "                           interp=False, tile=False, normalize=False)\n",
    "        total=get_wsi_level(wsi_cell,level_idx_cell)\n",
    "        end = time.time()\n",
    "        print('prediction time: {:.2f}'.format(end - start))\n",
    "        searched = [0] * len(masks)\n",
    "        for i in range(len(masks)):\n",
    "            if masks[i].max() <= 0:\n",
    "                searched[i] = 1\n",
    "                continue\n",
    "            overlap_indexes = get_overlap_patch_idx(fg_indexes[i], cols, rows) # i --> fg_indexes[i]\n",
    "            for overlap_idx in overlap_indexes:\n",
    "                if overlap_idx not in fg_indexes:\n",
    "                    continue\n",
    "                if masks[i].max() <= 0:\n",
    "                    searched[i] = 1\n",
    "                    break\n",
    "                overlap_idx_rel = fg_indexes.index(overlap_idx)\n",
    "                if searched[overlap_idx_rel]:  # if the overlap patch is searched\n",
    "                    continue\n",
    "                patch_xMin, patch_yMin, _, _ = patches_coord[fg_indexes[i]] # i --> fg_indexes[i]\n",
    "                patch2_xMin, patch2_yMin, _, _ = patches_coord[overlap_idx]\n",
    "                mask1, mask2 = clear_overlap(masks[i].copy(), masks[overlap_idx_rel].copy(), patch_xMin, patch_yMin, patch2_xMin, patch2_yMin)\n",
    "                masks[i] = mask1\n",
    "                masks[overlap_idx_rel] = mask2\n",
    "            searched[i] = 1\n",
    "        outlines = []\n",
    "        end1 = time.time()\n",
    "        print('filter time: {:.2f}'.format(end1 - end))\n",
    "        print(len(masks),len(patches_coord))\n",
    "        cell_list=[]\n",
    "        cell_area_list=[]\n",
    "        for i in range(len(patches_coord)):\n",
    "            outlines = outlines_list(masks[i], patches_coord[fg_indexes[i]][0], patches_coord[fg_indexes[i]][1])\n",
    "            cell=len(outlines)\n",
    "            mask_arr=sum(masks[i])\n",
    "            area=mask_arr*total *total\n",
    "            cell_list.append(cell)\n",
    "            cell_area_list.append(area)\n",
    "            for outline in outlines:\n",
    "                wsi_img[outline[:, 1], outline[:,0]] = np.array([255, 0, 0])\n",
    "        cv2.imwrite(os.path.join(output_path, Path(file).stem + '.jpg'), wsi_img[:,:, ::-1])\n",
    "        #files, extension = os.path.splitext(os.path.basename(file))\n",
    "        cell_number=sum(cell_list)\n",
    "        cell_area=sum(cell_area_list)\n",
    "        with open('Tissue_Cell_area.csv', 'a', encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)  \n",
    "            writer.writerow([file,tissue_area,cell_number,cell_area])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start20230718/1000384S01_HE.tif,read: 0.01, 512 3 2\n",
      "save successfully!  Total time:  2.520928144454956\n",
      "Start20230718/100013S01_HE.tif,read: 0.00, 512 3 2\n",
      "save successfully!  Total time:  0.9138245582580566\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.06\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.03\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.03\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.03\n",
      "inference:  0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: no mask pixels found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.03\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.03\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.01\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.02\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.04\n",
      "inference:  0.05\n",
      "inference:  0.05\n",
      "inference:  0.04\n",
      "inference:  0.02\n",
      "prediction time: 286.57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6185c22f32c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcell_wsi_area\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-b424936879f8>\u001b[0m in \u001b[0;36mcell_wsi_area\u001b[0;34m(img_file)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mpatch_xMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_yMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches_coord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfg_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# i --> fg_indexes[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mpatch2_xMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch2_yMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches_coord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moverlap_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mmask1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclear_overlap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moverlap_idx_rel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_xMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_yMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch2_xMin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch2_yMin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moverlap_idx_rel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d992859fa82d>\u001b[0m in \u001b[0;36mclear_overlap\u001b[0;34m(mask1, mask2, patch_xMin1, patch_yMin1, patch_xMin2, patch_yMin2)\u001b[0m\n\u001b[1;32m     24\u001b[0m                mask2_x_rel:(mask2_x_rel+mask2.shape[1])] = mask2\n\u001b[1;32m     25\u001b[0m         \u001b[0mcanvas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcanvas1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcanvas2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmask2_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         overlap_area = np.bincount(canvas[mask2_y_rel:(mask2_y_rel+mask2.shape[0]), \n\u001b[1;32m     28\u001b[0m                                           mask2_x_rel:(mask2_x_rel+mask2.shape[1])].reshape(-1))\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cell_wsi_area(img_file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
